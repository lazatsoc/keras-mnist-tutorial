{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_cnn.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j57TUN7l2lM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a24qXVd2qsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLzv5x-c2zL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "ac1d2657-cee8-4fbf-d794-07a0441013ea"
      },
      "source": [
        "plt.imshow(x_train[0], cmap='gray')\n",
        "plt.title('Class '+ str(y_train[0]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class 5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMuXwm2XK4TfLlMNvlimH3yxT/wd6nGDSY+sxFwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmGFJGOz3BqJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b226e617-5b33-473c-c8d6-5a24f1514f81"
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3UGb2mo3SwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjamW1a73XjJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "39fa3518-057d-4968-cfbf-048fce49fbb8"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqhzT2zF3gtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "e8a6a394-0f42-425f-b394-d32242f361d2"
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 184s 3ms/step - loss: 0.2607 - acc: 0.9193 - val_loss: 0.0639 - val_acc: 0.9790\n",
            "Epoch 2/12\n",
            "35200/60000 [================>.............] - ETA: 1:13 - loss: 0.0929 - acc: 0.9720"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}